{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference \n",
    "\n",
    "This notebook allows you to do: \n",
    "- ✅ **Inference**: Inference refers to using a trained model to make predictions on new, unseen data. This is the final step after training and evaluation, where the model is applied to real-world data.  \n",
    "   - ✅ **Define Data**: Define the path to a directory or image which you would like to have predictions for.  \n",
    "   - ✅ **Choose Model**: Choose a trained model which you would like to use for making predictions.  \n",
    "   - ✅ **Make Predictions**: Make predictions on the provided data using the selected model.\n",
    "\n",
    "---  \n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Execute the cell below to import external libraries, which simplify the implementation of the notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from IPython.display import display\n",
    "from deepEM.Utils import create_text_widget, print_info\n",
    "from src.Inferencer import Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Define Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In difference to other deep learning methods, a model needs to be trained for each tomogram you wish to reconstruct. This is the case due to the special nature of the approach: It is \"overfitting\" the model to the reconstructed sample itself. Hence, please make sure to execute `1_Development.ipynb` for each reconstruction. \n",
    "\n",
    "Then, you will not need to provide data for inference. The tomogram will be based on the data provided for training in `1_Development.ipynb`.\n",
    "\n",
    "> *Execute the cell below to visulize a text form to provdide the batch size for infernce.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_widget = create_text_widget(\"Batch Size:\", 16, \"Please set the batch size for inference. Larger batch size can lead to faster computation but may lead to OOM (out of memory) errors.\")\n",
    "\n",
    "display(*batch_widget)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Execute the cell below to set the Data Path accoring to your input in the text form above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(batch_widget[0].value)\n",
    "print_info(f\"Use batch size of {batch_size} for inference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Choose Model\n",
    "\n",
    "As mentioned above, due to the special nature of this deep learning approach, we require to retrain the model during inference. \n",
    "Still, we need to retrieve the best set of hyperparameters from our previous model developlent. \n",
    "These parameters were saved together with the model weights during the training.\n",
    "Hence, we are loading the model checkpoint.\n",
    "\n",
    "> *Execute the cell below to visulize a text form to provide the path to a trained model to do inference with.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_text_widget' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_widget \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_text_widget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Path:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the path to a pretrained model (i.e. logs/synthetic_2025-04-01_08-38-23/TrainingRun/checkpoints) which you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md like to use for inference.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m display(\u001b[38;5;241m*\u001b[39mmodel_widget)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_text_widget' is not defined"
     ]
    }
   ],
   "source": [
    "model_widget = create_text_widget(\"Model Path:\",\"\", \"Enter the path to a pretrained model (i.e. logs/synthetic_2025-04-01_08-38-23/TrainingRun/checkpoints) which you'd like to use for inference.\")\n",
    "display(*model_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Make Prediction\n",
    "> *Execute the cell below to generate the tomogram based on the data you specified earlier using the model you defined above. Results will be stored within the provided data folder.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = model_widget[0].value\n",
    "inferencer = Inference(model_path, None, batch_size)\n",
    "inferencer.inference()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepEM-tomography",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
