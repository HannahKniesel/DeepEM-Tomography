{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference \n",
    "Inference in deep learning is the process of using a trained model to make predictions on new, unseen data. It involves applying the learned parameters without further updates to generate outputs such as classifications or predictions.\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from IPython.display import display\n",
    "\n",
    "from deepEM.Utils import create_text_widget\n",
    "\n",
    "from src.Inferencer import Inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Define Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In difference to other deep learning methods, we will need to train a model also during inference. This is the case due to the special nature of the approach: It is \"overfitting\" the model to the reconstructed sample itself. \n",
    "\n",
    "Hence, for inference please provide a tilt series with following data structure: \n",
    "\n",
    "The data needs to be organized in a single folder containing a series of `.tif` files, which are sorted by their names. \n",
    "\n",
    "The folder further needs to contain a `.rawtlt` file with the tilt angles of the sinlge micrographs. The tilt angles are sorted based on the name sorting of the `.tif` files. When the data is currently in `.mrc` file format, you can generate a folder containing `.tif` images by using the `mrc2tif` command of the [iMOD](https://bio3d.colorado.edu/imod/) software or by using the [ImageJ](https://imagej.net/ij/) software. \n",
    "\n",
    "Lastly, we require a `metadata.json` with following content:\n",
    "\n",
    "```json \n",
    "{\n",
    "    \"slice_thickness_nm\": 550,\n",
    "    \"pixelsize_nmperpixel\": 1.0,\n",
    "    \"original_px_resolution\": 1000\n",
    "}\n",
    "```\n",
    "\n",
    " - `slice_theickness_nm` is the approximated slice thickness of your sample in [nm]. If you are uncertain, you should define an upper bound. \n",
    " - `pixelsize_nmperpixel` is the pixelsize of your dataset in [nm/px]. \n",
    " - `original_px_resolution` is the image resolution of a single `.tif` in your tilt series in [px]. \n",
    "\n",
    "\n",
    "You can generate such a `metadata.json` file, within any text editor of your choice. Add the above lines as content and adapt the parameters based on your data. Save the file as `metadata.json`. \n",
    "\n",
    "An example with a tilt series of five EM images and the corresponding `.rawtlt` and `metadata.json` is shown below: \n",
    "\n",
    "```\n",
    "data/\n",
    "├── image_001.tif\n",
    "├── image_002.tif\n",
    "├── image_003.tif\n",
    "├── image_004.tif\n",
    "├── image_005.tif\n",
    "├── metadata.json\n",
    "└── tilts.rawtlt\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_widget = create_text_widget(\"Data Path:\",\"data/real/noisy-projections\", \"Enter the path to a directory which contains .tif files you wish to do inference on.\")\n",
    "batch_widget = create_text_widget(\"Batch Size:\", 16, \"Please set the batch size for inference. Larger batch size can lead to faster computation but may lead to OOM (out of memory) errors.\")\n",
    "resize_widget = create_text_widget(\"Resize:\", 100, \"Downsizing the tilt series for faster model training. However, note that stonger downscaling leads to stronger loss of information..\")\n",
    "\n",
    "\n",
    "display(*data_widget)\n",
    "display(*batch_widget)\n",
    "display(*resize_widget)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = data_widget[0].value\n",
    "batch_size = int(batch_widget[0].value)\n",
    "resize = int(resize_widget[0].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Choose Model\n",
    "\n",
    "As mentioned above, due to the special nature of this deep learning approach, we require to retrain the model during inference. \n",
    "Still, we need to retrieve the best set of hyperparameters from our previous model developlent. \n",
    "These parameters were saved together with the model weights during the training.\n",
    "Hence, we are loading the model checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_widget = create_text_widget(\"Model Path:\",\"logs/synthetic_2025-03-25_17-49-28\", \"Enter the path to a pretrained model which you'd like to use for inference.\")\n",
    "display(*model_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Make Prediction\n",
    "By executing the cell below, your trained model will be used to make predictions on the defined data. The predictions will be saved inside the folder of your data at `<currentdatetime>`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = model_widget[0].value\n",
    "inferencer = Inference(model_path, data_path, batch_size, resize)\n",
    "inferencer.inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepEM-tomography",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
