{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development \n",
    "\n",
    "\n",
    "## 2D to 3D  \n",
    "\n",
    "### Primary Focus: Tomographic Reconstruction   \n",
    "### Application: Tomographic Reconstruction of STEM tilt series\n",
    "\n",
    "#### Challenge: Evaluation with missing ground truth    \n",
    "#### Required Labels: None\n",
    "\n",
    "TL;DR ðŸ§¬âœ¨ We use deep learning for tomographic reconstruction of 2D STEM projections, following [1,2]. This approach enables 3D volume reconstruction, revealing detailed cellular structures and relationships not visible in 2D.\n",
    "\n",
    "![Teaser](./images/Teaser.gif)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# imports from the template \n",
    "from deepEM.Utils import create_text_widget, print_info, find_file\n",
    "from deepEM.Logger import Logger\n",
    "from deepEM.ModelTuner import ModelTuner\n",
    "\n",
    "# costum implementation\n",
    "from src.ModelTrainer import ModelTrainer\n",
    "\n",
    "\n",
    "# import all required libraries\n",
    "from pathlib import Path \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.1 Data Acquisition  \n",
    "\n",
    "In the case of tomographic reconstruction we do not have access to ground truth information (the 3D structure of the underlying sample). Still, it is important to verify the applicability of the deep learning method. Hence, the use of synthetic data to prove the correctness of the approach and estimate errors. \n",
    "Luckily, we do not need to generate data from scratch, but we can make use of existing synthetic data [1].\n",
    "\n",
    "*[1] Kniesel, Hannah, et al. \"Clean implicit 3d structure from noisy 2d stem images.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.2. Data Anntation\n",
    "\n",
    "The applied deep learning method for tomographic reconstruction is a self-supervised appraoch, which means that we do not need annotated data during training of the neural network. \n",
    "Similarly, as we are working with synthetic data, no annotated data is needed for the evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.3. Data Preprocessing\n",
    "\n",
    "If you wish to reconstruct your own tomogram using the provided notebook, these are the preprocessing steps you need to do:\n",
    "\n",
    "1. **Data Alignment**: As there are usually very small deviations of the image alignment between different acquistion angles, the data should be aligned before reconstruction. While [ImageJ](https://imagej.net/ij/) provides data alignment using SIFT, we usually recommend to use more sophisticated approaches like the tracking of gold particles for alignment (for example by using [iMOD](https://bio3d.colorado.edu/imod/)), to get the best results.\n",
    "\n",
    "2. **Tilt Axis Correction**: In some cases, the tilt axis can be slightly tilted off the main central vertical axis. This needs to be corrected before applying the reconstruction algorithm.\n",
    "Additionally, we require the tilt axis to be vertical. When a horizontal tilt axis is provided, software like [ImageJ](https://imagej.net/ij/) can be used to rotate the images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Data Structuring\n",
    "\n",
    "We require the data to be organized in a single folder containing a series of `.tif` files, which are sorted by their names. \n",
    "\n",
    "The folder further needs to contain a `.rawtlt` file with the tilt angles of the EM. When the data is currently in `.mrc` file format, this can be achieved by using the `mrc2tif` command of the [iMOD](https://bio3d.colorado.edu/imod/) software or by using the [ImageJ](https://imagej.net/ij/) software. \n",
    "\n",
    "Lastly, we require a `metadata.json` with following content:\n",
    "\n",
    "```json \n",
    "{\n",
    "    \"slice_thickness_nm\": 550,\n",
    "    \"pixelsize_nmperpixel\": 1.0,\n",
    "    \"original_px_resolution\": 1000\n",
    "}\n",
    "```\n",
    "\n",
    " - `slice_theickness_nm` is the approximated slice thickness of your sample in [nm]. \n",
    " - `pixelsize_nmperpixel` is the pixelsize of your dataset in [nm/px]. \n",
    " - `original_px_resolution` is the image resolution of a single `.tif` in your tilt series in [px]. \n",
    "\n",
    "\n",
    "You can generate such file, within any text editor of your choice. Add the above lines of content and adapt the parameters based on your data. Save the file as `metadata.json`. \n",
    "\n",
    "### Synthetic Data\n",
    "Due to the missing ground truth information on real data, model development will be done on synthetic data. The synthetic data consists of a noisy tilt series, which is used for training and a clean tilt series which is used for evaluation. Additionally, we use the phantom volume (hence the ground truth underlying sample of the synthetic data) for evaluation purposes.\n",
    "\n",
    "An example with a tilt series of five EM images and the corresponding `.rawtlt` and `metadata.json` is shown below: \n",
    "\n",
    "```\n",
    "data/\n",
    "â”œâ”€â”€ noisy-projections\n",
    "    â”œâ”€â”€ image_001.tif\n",
    "    â”œâ”€â”€ image_002.tif\n",
    "    â”œâ”€â”€ image_003.tif\n",
    "    â”œâ”€â”€ image_004.tif\n",
    "    â”œâ”€â”€ image_005.tif\n",
    "    â”œâ”€â”€ metadata.json\n",
    "    â””â”€â”€ tilts.rawtlt\n",
    "â”œâ”€â”€ clean-projections\n",
    "    â”œâ”€â”€ image_001.tif\n",
    "    â”œâ”€â”€ image_002.tif\n",
    "    â”œâ”€â”€ image_003.tif\n",
    "    â”œâ”€â”€ image_004.tif\n",
    "    â”œâ”€â”€ image_005.tif\n",
    "    â”œâ”€â”€ metadata.json\n",
    "    â””â”€â”€ tilts.rawtlt\n",
    "â””â”€â”€ phantom-volume\n",
    "    â””â”€â”€ volume.raw\n",
    "\n",
    "```\n",
    "For details please check the provided data within this use case.\n",
    "\n",
    "\n",
    "If you are using different data than the one provided (`data/`), we require you to set the path to this folder. To do so, adapt the path in the text form below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9cd2e9219164ae29d9a04aabb9695e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='./data/synthetic', description='Data Path:', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3789434c7e20417c99f3102fc8967310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>Hint:</b> Enter the path to your data folder.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_widget = create_text_widget(\"Data Path:\",\"./data/synthetic\",\"Enter the path to your data folder.\")\n",
    "display(*data_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]::Data path was set to: ./data/synthetic\n"
     ]
    }
   ],
   "source": [
    "data_path = data_widget[0].value\n",
    "print(f\"[INFO]::Data path was set to: {data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Setup Logging\n",
    "\n",
    "By executing the cell below, we setup the logging directory for model training and evaluation. \n",
    "The logger creates a folder at `./logs/<datafoldername>-<currentdatetime>/`. \n",
    "Within this folder there will be logging of: \n",
    "\n",
    "- the used hyperparameters, (`<log-path>/TrainingRun/hyperparameters.json`)\n",
    "- the best performing model checkpoint based on the validation loss (`<log-path>/TrainingRun/checkpoints/best_model.pth`)\n",
    "- the last model checkpoint (`<log-path>/TrainingRun/checkpoints/latest_model.pth`)\n",
    "- visualizations of training and validation curves (`<log-path>/TrainingRun/plots/training_curves.png`)\n",
    "- qualitative visualization of sampled validation images (`<log-path>/TrainingRun/samples/`)\n",
    "- results on test metrics (`<log-path>/TrainingRun/test_results.txt`)\n",
    "- qualitative visualization of sampled test images (`<log-path>/TrainingRun/samples/`)\n",
    "\n",
    "Additional text logs are being saved to `<log-path>/TrainingRun/log.txt` and `<log-path>/log.txt` \n",
    "\n",
    "During validation we visualize a synthetic EM image, generated from the currently learned reconstruction and the corresponding real EM image next to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger initialized. Logs will be saved to: logs/synthetic_2025-03-25_17-49-28\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Hyperparameter Tuning\n",
    "\n",
    "\n",
    "Hyperparameters in deep learning are configurable settings that define how a model is trained. Unlike model parameters, they are set before training and not learned from the data.\n",
    "\n",
    "When training a model, we highly recommend to do a hyperparameter tuning first. By tuning the hyperparameters the model is usually trained on a subset of the data with a smaller number of epochs, and then evaluated based on its performance on the validation set. Then, hyperparameters, which lead to the best performance are chosen for full training of the model. \n",
    "Similar to the training run, all sweep runs will be logged. You can find the according logs at `<log-path>/Sweep-<idx>`.\n",
    "\n",
    "Our workflow equips you, as EM experts, with an automatic hyperparameter search based on a grid search. The DL experts have chosen some basic setting for performing the hyperparameter seach and defining the search space. The DL experts also describe the individual hyperparameters. This allows you to further adapt the search space to your specific needs. \n",
    "\n",
    "In order to do so, you can adapt the form below. Each sweep parameter should be separated by `,`. Floating point values should be written like `0.1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7393c8d7e8744ba392f8cef8a9421664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h1>Hyperparameter Sweep</h1>                              <p>A hyperparameter sweeâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hyperparameter search\n",
    "model_trainer = ModelTrainer(data_path, logger)\n",
    "\n",
    "hyperparameter_tuner = ModelTuner(model_trainer, logger)\n",
    "form = hyperparameter_tuner.create_hyperparameter_widgets()\n",
    "display(form)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to run a hyperparameter sweep based on the parameters above, please execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 17:49:28,208 - INFO - Start hyperparameter sweep...\n",
      "2025-03-25 17:49:28,209 - INFO - Start Sweep 1 of 6...\n",
      "2025-03-25 17:49:28,209 - INFO - Current hyperparams {'learning_rate': 0.0005, 'batch_size': 4, 'resize': 100}\n",
      "2025-03-25 17:49:28,210 - INFO - Hyperparameters saved to logs/synthetic_2025-03-25_17-49-28/Sweep_0/hyperparameters.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweep config:\n",
      "\tlearning_rate: [0.0005, 5e-05, 5e-06] (default: 5e-05)\n",
      "\tbatch_size: [4, 8] (default: 4)\n",
      "\tresize: [100] (default: 100)\n",
      "Logger initialized. Logs will be saved to: logs/synthetic_2025-03-25_17-49-28/Sweep_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 17:49:28,454 - INFO - Model was setup.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::Found 94 images within tilt series at ./data/synthetic/noisy-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/noisy-projections/tilt.rawtlt\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 20% for validation, resulting in 18 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 17:49:31,962 - INFO - Start Training | Epoch: 5 | Dataset size: 940000 | Parameters: {'epochs': 25, 'early_stopping_patience': 5, 'validation_interval': 5, 'scheduler_step_by': 'epoch', 'images_to_visualize': 4, 'pos_enc': 5, 'accum_gradients': 4, 'batch_size': 4, 'beam_samples': 64, 'learning_rate': 0.0005, 'resize': 100} \n",
      "/media/hansel/SSD/Code/PaulFestschrift/Deep-EM Playground/Tomogram/src/STEM.py:80: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  offset = torch.cuda.FloatTensor(batch_size, beam_samples*2).uniform_(float(-bin_size/2), float(bin_size/2))\n",
      "2025-03-25 18:07:55,229 - INFO - Epoch 0 - Training loss: 0.0059\n",
      "2025-03-25 18:08:19,252 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_0/samples/validation_epoch-0_*\n",
      "2025-03-25 18:10:01,511 - INFO - Epoch 0 - Validation loss: 0.0085, MSE: 0.0085\n",
      "2025-03-25 18:10:01,522 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_0/checkpoints/latest_model.pth\n",
      "2025-03-25 18:10:01,533 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_0/checkpoints/best_model.pth (Validation Loss: 0.0085)\n",
      "2025-03-25 18:10:01,534 - INFO - Avg time single epoch: 0h20m29s | Remaining time training: 1h21m58s\n",
      "2025-03-25 18:10:01,600 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_0/plots/training_curves.png\n",
      "2025-03-25 18:28:15,803 - INFO - Epoch 1 - Training loss: 0.0052\n",
      "2025-03-25 18:28:39,713 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_0/samples/validation_epoch-1_*\n",
      "2025-03-25 18:30:29,794 - INFO - Epoch 1 - Validation loss: 0.0066, MSE: 0.0066\n",
      "2025-03-25 18:30:29,806 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_0/checkpoints/latest_model.pth\n",
      "2025-03-25 18:30:29,819 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_0/checkpoints/best_model.pth (Validation Loss: 0.0066)\n",
      "2025-03-25 18:30:29,820 - INFO - Avg time single epoch: 0h20m28s | Remaining time training: 1h1m26s\n",
      "2025-03-25 18:30:29,901 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_0/plots/training_curves.png\n",
      "2025-03-25 18:48:50,528 - INFO - Epoch 2 - Training loss: 0.0051\n",
      "2025-03-25 18:49:13,895 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_0/samples/validation_epoch-2_*\n",
      "2025-03-25 18:51:03,430 - INFO - Epoch 2 - Validation loss: 0.0068, MSE: 0.0068\n",
      "2025-03-25 18:51:03,443 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_0/checkpoints/latest_model.pth\n",
      "2025-03-25 18:51:03,443 - INFO - No improvement in validation loss. Patience counter: 1/5\n",
      "2025-03-25 18:51:03,444 - INFO - Avg time single epoch: 0h20m30s | Remaining time training: 0h41m0s\n",
      "2025-03-25 18:51:03,536 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_0/plots/training_curves.png\n",
      "2025-03-25 19:09:26,876 - INFO - Epoch 3 - Training loss: 0.0051\n",
      "2025-03-25 19:09:50,596 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_0/samples/validation_epoch-3_*\n",
      "2025-03-25 19:11:35,604 - INFO - Epoch 3 - Validation loss: 0.0080, MSE: 0.0080\n",
      "2025-03-25 19:11:35,616 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_0/checkpoints/latest_model.pth\n",
      "2025-03-25 19:11:35,617 - INFO - No improvement in validation loss. Patience counter: 2/5\n",
      "2025-03-25 19:11:35,618 - INFO - Avg time single epoch: 0h20m30s | Remaining time training: 0h20m30s\n",
      "2025-03-25 19:11:35,705 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_0/plots/training_curves.png\n",
      "2025-03-25 19:29:57,452 - INFO - Epoch 4 - Training loss: 0.0051\n",
      "2025-03-25 19:30:19,527 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_0/samples/validation_epoch-4_*\n",
      "2025-03-25 19:31:58,757 - INFO - Epoch 4 - Validation loss: 0.0066, MSE: 0.0066\n",
      "2025-03-25 19:31:58,769 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_0/checkpoints/latest_model.pth\n",
      "2025-03-25 19:31:58,781 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_0/checkpoints/best_model.pth (Validation Loss: 0.0066)\n",
      "2025-03-25 19:31:58,782 - INFO - Avg time single epoch: 0h20m29s | Remaining time training: 0h0m0s\n",
      "2025-03-25 19:31:58,867 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_0/plots/training_curves.png\n",
      "2025-03-25 19:31:58,868 - INFO - Hyperparameters: {'learning_rate': 0.0005, 'batch_size': 4, 'resize': 100}, Validation Loss: 0.006567244238856178\n",
      "2025-03-25 19:31:58,868 - INFO - Avg time single sweep: 1h42m26s | Remaining_time: 8h32m14s\n",
      "2025-03-25 19:31:58,869 - INFO - Updated best sweep parameters saved to ./data/synthetic/Sweep_Parameters/best_sweep_parameters.json\n",
      "2025-03-25 19:31:58,871 - INFO - Start Sweep 2 of 6...\n",
      "2025-03-25 19:31:58,871 - INFO - Current hyperparams {'learning_rate': 0.0005, 'batch_size': 8, 'resize': 100}\n",
      "2025-03-25 19:31:58,872 - INFO - Hyperparameters saved to logs/synthetic_2025-03-25_17-49-28/Sweep_1/hyperparameters.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger initialized. Logs will be saved to: logs/synthetic_2025-03-25_17-49-28/Sweep_1\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/noisy-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/noisy-projections/tilt.rawtlt\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 20% for validation, resulting in 18 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 19:32:01,551 - INFO - Start Training | Epoch: 5 | Dataset size: 940000 | Parameters: {'epochs': 25, 'early_stopping_patience': 5, 'validation_interval': 5, 'scheduler_step_by': 'epoch', 'images_to_visualize': 4, 'pos_enc': 5, 'accum_gradients': 4, 'batch_size': 8, 'beam_samples': 64, 'learning_rate': 0.0005, 'resize': 100} \n",
      "2025-03-25 19:41:45,900 - INFO - Epoch 0 - Training loss: 0.0062\n",
      "2025-03-25 19:41:58,454 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_1/samples/validation_epoch-0_*\n",
      "2025-03-25 19:42:55,329 - INFO - Epoch 0 - Validation loss: 0.0087, MSE: 0.0087\n",
      "2025-03-25 19:42:55,341 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_1/checkpoints/latest_model.pth\n",
      "2025-03-25 19:42:55,354 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_1/checkpoints/best_model.pth (Validation Loss: 0.0087)\n",
      "2025-03-25 19:42:55,354 - INFO - Avg time single epoch: 0h10m53s | Remaining time training: 0h43m35s\n",
      "2025-03-25 19:42:55,427 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_1/plots/training_curves.png\n",
      "2025-03-25 19:52:27,502 - INFO - Epoch 1 - Training loss: 0.0056\n",
      "2025-03-25 19:52:39,882 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_1/samples/validation_epoch-1_*\n",
      "2025-03-25 19:53:33,731 - INFO - Epoch 1 - Validation loss: 0.0068, MSE: 0.0068\n",
      "2025-03-25 19:53:33,743 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_1/checkpoints/latest_model.pth\n",
      "2025-03-25 19:53:33,759 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_1/checkpoints/best_model.pth (Validation Loss: 0.0068)\n",
      "2025-03-25 19:53:33,760 - INFO - Avg time single epoch: 0h10m46s | Remaining time training: 0h32m18s\n",
      "2025-03-25 19:53:33,842 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_1/plots/training_curves.png\n",
      "2025-03-25 20:03:13,842 - INFO - Epoch 2 - Training loss: 0.0055\n",
      "2025-03-25 20:03:26,627 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_1/samples/validation_epoch-2_*\n",
      "2025-03-25 20:04:23,732 - INFO - Epoch 2 - Validation loss: 0.0070, MSE: 0.0070\n",
      "2025-03-25 20:04:23,746 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_1/checkpoints/latest_model.pth\n",
      "2025-03-25 20:04:23,747 - INFO - No improvement in validation loss. Patience counter: 1/5\n",
      "2025-03-25 20:04:23,748 - INFO - Avg time single epoch: 0h10m47s | Remaining time training: 0h21m34s\n",
      "2025-03-25 20:04:23,837 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_1/plots/training_curves.png\n",
      "2025-03-25 20:13:53,429 - INFO - Epoch 3 - Training loss: 0.0054\n",
      "2025-03-25 20:14:06,391 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_1/samples/validation_epoch-3_*\n",
      "2025-03-25 20:15:03,930 - INFO - Epoch 3 - Validation loss: 0.0073, MSE: 0.0073\n",
      "2025-03-25 20:15:03,942 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_1/checkpoints/latest_model.pth\n",
      "2025-03-25 20:15:03,943 - INFO - No improvement in validation loss. Patience counter: 2/5\n",
      "2025-03-25 20:15:03,943 - INFO - Avg time single epoch: 0h10m45s | Remaining time training: 0h10m45s\n",
      "2025-03-25 20:15:04,027 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_1/plots/training_curves.png\n",
      "2025-03-25 20:24:39,702 - INFO - Epoch 4 - Training loss: 0.0054\n",
      "2025-03-25 20:24:52,575 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_1/samples/validation_epoch-4_*\n",
      "2025-03-25 20:25:50,042 - INFO - Epoch 4 - Validation loss: 0.0064, MSE: 0.0064\n",
      "2025-03-25 20:25:50,054 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_1/checkpoints/latest_model.pth\n",
      "2025-03-25 20:25:50,067 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_1/checkpoints/best_model.pth (Validation Loss: 0.0064)\n",
      "2025-03-25 20:25:50,067 - INFO - Avg time single epoch: 0h10m45s | Remaining time training: 0h0m0s\n",
      "2025-03-25 20:25:50,156 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_1/plots/training_curves.png\n",
      "2025-03-25 20:25:50,157 - INFO - Hyperparameters: {'learning_rate': 0.0005, 'batch_size': 8, 'resize': 100}, Validation Loss: 0.006426070013358877\n",
      "2025-03-25 20:25:50,157 - INFO - Avg time single sweep: 1h18m7s | Remaining_time: 5h12m31s\n",
      "2025-03-25 20:25:50,158 - INFO - Updated best sweep parameters saved to ./data/synthetic/Sweep_Parameters/best_sweep_parameters.json\n",
      "2025-03-25 20:25:50,159 - INFO - Start Sweep 3 of 6...\n",
      "2025-03-25 20:25:50,160 - INFO - Current hyperparams {'learning_rate': 5e-05, 'batch_size': 4, 'resize': 100}\n",
      "2025-03-25 20:25:50,161 - INFO - Hyperparameters saved to logs/synthetic_2025-03-25_17-49-28/Sweep_2/hyperparameters.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger initialized. Logs will be saved to: logs/synthetic_2025-03-25_17-49-28/Sweep_2\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/noisy-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/noisy-projections/tilt.rawtlt\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 20% for validation, resulting in 18 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 20:25:52,786 - INFO - Start Training | Epoch: 5 | Dataset size: 940000 | Parameters: {'epochs': 25, 'early_stopping_patience': 5, 'validation_interval': 5, 'scheduler_step_by': 'epoch', 'images_to_visualize': 4, 'pos_enc': 5, 'accum_gradients': 4, 'batch_size': 4, 'beam_samples': 64, 'learning_rate': 5e-05, 'resize': 100} \n",
      "2025-03-25 20:44:21,202 - INFO - Epoch 0 - Training loss: 0.0063\n",
      "2025-03-25 20:44:45,175 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_2/samples/validation_epoch-0_*\n",
      "2025-03-25 20:46:28,310 - INFO - Epoch 0 - Validation loss: 0.0095, MSE: 0.0095\n",
      "2025-03-25 20:46:28,321 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_2/checkpoints/latest_model.pth\n",
      "2025-03-25 20:46:28,333 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_2/checkpoints/best_model.pth (Validation Loss: 0.0095)\n",
      "2025-03-25 20:46:28,334 - INFO - Avg time single epoch: 0h20m35s | Remaining time training: 1h22m22s\n",
      "2025-03-25 20:46:28,414 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_2/plots/training_curves.png\n",
      "2025-03-25 21:04:51,575 - INFO - Epoch 1 - Training loss: 0.0053\n",
      "2025-03-25 21:05:15,231 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_2/samples/validation_epoch-1_*\n",
      "2025-03-25 21:07:03,915 - INFO - Epoch 1 - Validation loss: 0.0068, MSE: 0.0068\n",
      "2025-03-25 21:07:03,934 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_2/checkpoints/latest_model.pth\n",
      "2025-03-25 21:07:03,950 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_2/checkpoints/best_model.pth (Validation Loss: 0.0068)\n",
      "2025-03-25 21:07:03,951 - INFO - Avg time single epoch: 0h20m35s | Remaining time training: 1h1m46s\n",
      "2025-03-25 21:07:04,022 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_2/plots/training_curves.png\n",
      "2025-03-25 21:25:37,892 - INFO - Epoch 2 - Training loss: 0.0051\n",
      "2025-03-25 21:26:01,169 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_2/samples/validation_epoch-2_*\n",
      "2025-03-25 21:27:46,789 - INFO - Epoch 2 - Validation loss: 0.0067, MSE: 0.0067\n",
      "2025-03-25 21:27:46,801 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_2/checkpoints/latest_model.pth\n",
      "2025-03-25 21:27:46,814 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_2/checkpoints/best_model.pth (Validation Loss: 0.0067)\n",
      "2025-03-25 21:27:46,815 - INFO - Avg time single epoch: 0h20m37s | Remaining time training: 0h41m15s\n",
      "2025-03-25 21:27:46,896 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_2/plots/training_curves.png\n",
      "2025-03-25 21:46:28,491 - INFO - Epoch 3 - Training loss: 0.0051\n",
      "2025-03-25 21:46:50,690 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_2/samples/validation_epoch-3_*\n",
      "2025-03-25 21:48:38,598 - INFO - Epoch 3 - Validation loss: 0.0089, MSE: 0.0089\n",
      "2025-03-25 21:48:38,610 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_2/checkpoints/latest_model.pth\n",
      "2025-03-25 21:48:38,611 - INFO - No improvement in validation loss. Patience counter: 1/5\n",
      "2025-03-25 21:48:38,612 - INFO - Avg time single epoch: 0h20m41s | Remaining time training: 0h20m41s\n",
      "2025-03-25 21:48:38,699 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_2/plots/training_curves.png\n",
      "2025-03-25 22:07:07,232 - INFO - Epoch 4 - Training loss: 0.0050\n",
      "2025-03-25 22:07:30,727 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_2/samples/validation_epoch-4_*\n",
      "2025-03-25 22:09:19,510 - INFO - Epoch 4 - Validation loss: 0.0071, MSE: 0.0071\n",
      "2025-03-25 22:09:19,522 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_2/checkpoints/latest_model.pth\n",
      "2025-03-25 22:09:19,523 - INFO - No improvement in validation loss. Patience counter: 2/5\n",
      "2025-03-25 22:09:19,524 - INFO - Avg time single epoch: 0h20m41s | Remaining time training: 0h0m0s\n",
      "2025-03-25 22:09:19,607 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_2/plots/training_curves.png\n",
      "2025-03-25 22:09:19,607 - INFO - Hyperparameters: {'learning_rate': 5e-05, 'batch_size': 4, 'resize': 100}, Validation Loss: 0.0066888444185723255\n",
      "2025-03-25 22:09:19,608 - INFO - Avg time single sweep: 1h26m34s | Remaining_time: 4h19m42s\n",
      "2025-03-25 22:09:19,609 - INFO - Start Sweep 4 of 6...\n",
      "2025-03-25 22:09:19,609 - INFO - Current hyperparams {'learning_rate': 5e-05, 'batch_size': 8, 'resize': 100}\n",
      "2025-03-25 22:09:19,610 - INFO - Hyperparameters saved to logs/synthetic_2025-03-25_17-49-28/Sweep_3/hyperparameters.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger initialized. Logs will be saved to: logs/synthetic_2025-03-25_17-49-28/Sweep_3\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/noisy-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/noisy-projections/tilt.rawtlt\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 20% for validation, resulting in 18 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 22:09:22,267 - INFO - Start Training | Epoch: 5 | Dataset size: 940000 | Parameters: {'epochs': 25, 'early_stopping_patience': 5, 'validation_interval': 5, 'scheduler_step_by': 'epoch', 'images_to_visualize': 4, 'pos_enc': 5, 'accum_gradients': 4, 'batch_size': 8, 'beam_samples': 64, 'learning_rate': 5e-05, 'resize': 100} \n",
      "2025-03-25 22:19:00,958 - INFO - Epoch 0 - Training loss: 0.0071\n",
      "2025-03-25 22:19:13,238 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_3/samples/validation_epoch-0_*\n",
      "2025-03-25 22:20:09,281 - INFO - Epoch 0 - Validation loss: 0.0079, MSE: 0.0079\n",
      "2025-03-25 22:20:09,292 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_3/checkpoints/latest_model.pth\n",
      "2025-03-25 22:20:09,303 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_3/checkpoints/best_model.pth (Validation Loss: 0.0079)\n",
      "2025-03-25 22:20:09,304 - INFO - Avg time single epoch: 0h10m47s | Remaining time training: 0h43m8s\n",
      "2025-03-25 22:20:09,386 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_3/plots/training_curves.png\n",
      "2025-03-25 22:29:36,978 - INFO - Epoch 1 - Training loss: 0.0057\n",
      "2025-03-25 22:29:48,808 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_3/samples/validation_epoch-1_*\n",
      "2025-03-25 22:30:45,785 - INFO - Epoch 1 - Validation loss: 0.0064, MSE: 0.0064\n",
      "2025-03-25 22:30:45,798 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_3/checkpoints/latest_model.pth\n",
      "2025-03-25 22:30:45,811 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_3/checkpoints/best_model.pth (Validation Loss: 0.0064)\n",
      "2025-03-25 22:30:45,811 - INFO - Avg time single epoch: 0h10m41s | Remaining time training: 0h32m5s\n",
      "2025-03-25 22:30:45,884 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_3/plots/training_curves.png\n",
      "2025-03-25 22:40:13,839 - INFO - Epoch 2 - Training loss: 0.0056\n",
      "2025-03-25 22:40:26,137 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_3/samples/validation_epoch-2_*\n",
      "2025-03-25 22:41:20,946 - INFO - Epoch 2 - Validation loss: 0.0070, MSE: 0.0070\n",
      "2025-03-25 22:41:20,959 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_3/checkpoints/latest_model.pth\n",
      "2025-03-25 22:41:20,960 - INFO - No improvement in validation loss. Patience counter: 1/5\n",
      "2025-03-25 22:41:20,961 - INFO - Avg time single epoch: 0h10m39s | Remaining time training: 0h21m19s\n",
      "2025-03-25 22:41:21,047 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_3/plots/training_curves.png\n",
      "2025-03-25 22:50:58,181 - INFO - Epoch 3 - Training loss: 0.0055\n",
      "2025-03-25 22:51:11,036 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_3/samples/validation_epoch-3_*\n",
      "2025-03-25 22:52:08,173 - INFO - Epoch 3 - Validation loss: 0.0071, MSE: 0.0071\n",
      "2025-03-25 22:52:08,185 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_3/checkpoints/latest_model.pth\n",
      "2025-03-25 22:52:08,185 - INFO - No improvement in validation loss. Patience counter: 2/5\n",
      "2025-03-25 22:52:08,186 - INFO - Avg time single epoch: 0h10m41s | Remaining time training: 0h10m41s\n",
      "2025-03-25 22:52:08,267 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_3/plots/training_curves.png\n",
      "2025-03-25 23:01:32,089 - INFO - Epoch 4 - Training loss: 0.0054\n",
      "2025-03-25 23:01:45,014 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_3/samples/validation_epoch-4_*\n",
      "2025-03-25 23:02:41,730 - INFO - Epoch 4 - Validation loss: 0.0060, MSE: 0.0060\n",
      "2025-03-25 23:02:41,742 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_3/checkpoints/latest_model.pth\n",
      "2025-03-25 23:02:41,754 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_3/checkpoints/best_model.pth (Validation Loss: 0.0060)\n",
      "2025-03-25 23:02:41,755 - INFO - Avg time single epoch: 0h10m39s | Remaining time training: 0h0m0s\n",
      "2025-03-25 23:02:41,839 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_3/plots/training_curves.png\n",
      "2025-03-25 23:02:41,839 - INFO - Hyperparameters: {'learning_rate': 5e-05, 'batch_size': 8, 'resize': 100}, Validation Loss: 0.006018673521477177\n",
      "2025-03-25 23:02:41,840 - INFO - Avg time single sweep: 1h18m15s | Remaining_time: 2h36m30s\n",
      "2025-03-25 23:02:41,841 - INFO - Updated best sweep parameters saved to ./data/synthetic/Sweep_Parameters/best_sweep_parameters.json\n",
      "2025-03-25 23:02:41,841 - INFO - Start Sweep 5 of 6...\n",
      "2025-03-25 23:02:41,842 - INFO - Current hyperparams {'learning_rate': 5e-06, 'batch_size': 4, 'resize': 100}\n",
      "2025-03-25 23:02:41,843 - INFO - Hyperparameters saved to logs/synthetic_2025-03-25_17-49-28/Sweep_4/hyperparameters.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger initialized. Logs will be saved to: logs/synthetic_2025-03-25_17-49-28/Sweep_4\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/noisy-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/noisy-projections/tilt.rawtlt\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 20% for validation, resulting in 18 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 23:02:44,577 - INFO - Start Training | Epoch: 5 | Dataset size: 940000 | Parameters: {'epochs': 25, 'early_stopping_patience': 5, 'validation_interval': 5, 'scheduler_step_by': 'epoch', 'images_to_visualize': 4, 'pos_enc': 5, 'accum_gradients': 4, 'batch_size': 4, 'beam_samples': 64, 'learning_rate': 5e-06, 'resize': 100} \n",
      "2025-03-25 23:20:57,606 - INFO - Epoch 0 - Training loss: 0.0098\n",
      "2025-03-25 23:21:19,453 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_4/samples/validation_epoch-0_*\n",
      "2025-03-25 23:23:05,764 - INFO - Epoch 0 - Validation loss: 0.0085, MSE: 0.0085\n",
      "2025-03-25 23:23:05,775 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_4/checkpoints/latest_model.pth\n",
      "2025-03-25 23:23:05,786 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_4/checkpoints/best_model.pth (Validation Loss: 0.0085)\n",
      "2025-03-25 23:23:05,787 - INFO - Avg time single epoch: 0h20m21s | Remaining time training: 1h21m24s\n",
      "2025-03-25 23:23:05,854 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_4/plots/training_curves.png\n",
      "2025-03-25 23:41:31,174 - INFO - Epoch 1 - Training loss: 0.0065\n",
      "2025-03-25 23:41:54,092 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_4/samples/validation_epoch-1_*\n",
      "2025-03-25 23:43:36,655 - INFO - Epoch 1 - Validation loss: 0.0070, MSE: 0.0070\n",
      "2025-03-25 23:43:36,669 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_4/checkpoints/latest_model.pth\n",
      "2025-03-25 23:43:36,682 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_4/checkpoints/best_model.pth (Validation Loss: 0.0070)\n",
      "2025-03-25 23:43:36,683 - INFO - Avg time single epoch: 0h20m26s | Remaining time training: 1h1m18s\n",
      "2025-03-25 23:43:36,756 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_4/plots/training_curves.png\n",
      "2025-03-26 00:02:00,271 - INFO - Epoch 2 - Training loss: 0.0061\n",
      "2025-03-26 00:02:24,040 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_4/samples/validation_epoch-2_*\n",
      "2025-03-26 00:04:09,196 - INFO - Epoch 2 - Validation loss: 0.0076, MSE: 0.0076\n",
      "2025-03-26 00:04:09,207 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_4/checkpoints/latest_model.pth\n",
      "2025-03-26 00:04:09,208 - INFO - No improvement in validation loss. Patience counter: 1/5\n",
      "2025-03-26 00:04:09,209 - INFO - Avg time single epoch: 0h20m28s | Remaining time training: 0h40m56s\n",
      "2025-03-26 00:04:09,298 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_4/plots/training_curves.png\n",
      "2025-03-26 00:22:35,109 - INFO - Epoch 3 - Training loss: 0.0058\n",
      "2025-03-26 00:22:56,719 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_4/samples/validation_epoch-3_*\n",
      "2025-03-26 00:24:38,915 - INFO - Epoch 3 - Validation loss: 0.0087, MSE: 0.0087\n",
      "2025-03-26 00:24:38,927 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_4/checkpoints/latest_model.pth\n",
      "2025-03-26 00:24:38,928 - INFO - No improvement in validation loss. Patience counter: 2/5\n",
      "2025-03-26 00:24:38,929 - INFO - Avg time single epoch: 0h20m28s | Remaining time training: 0h20m28s\n",
      "2025-03-26 00:24:39,012 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_4/plots/training_curves.png\n",
      "2025-03-26 00:43:07,559 - INFO - Epoch 4 - Training loss: 0.0056\n",
      "2025-03-26 00:43:29,950 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_4/samples/validation_epoch-4_*\n",
      "2025-03-26 00:45:17,365 - INFO - Epoch 4 - Validation loss: 0.0071, MSE: 0.0071\n",
      "2025-03-26 00:45:17,376 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_4/checkpoints/latest_model.pth\n",
      "2025-03-26 00:45:17,377 - INFO - No improvement in validation loss. Patience counter: 3/5\n",
      "2025-03-26 00:45:17,377 - INFO - Avg time single epoch: 0h20m30s | Remaining time training: 0h0m0s\n",
      "2025-03-26 00:45:17,449 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_4/plots/training_curves.png\n",
      "2025-03-26 00:45:17,450 - INFO - Hyperparameters: {'learning_rate': 5e-06, 'batch_size': 4, 'resize': 100}, Validation Loss: 0.00698907062167422\n",
      "2025-03-26 00:45:17,451 - INFO - Avg time single sweep: 1h23m6s | Remaining_time: 1h23m6s\n",
      "2025-03-26 00:45:17,452 - INFO - Start Sweep 6 of 6...\n",
      "2025-03-26 00:45:17,453 - INFO - Current hyperparams {'learning_rate': 5e-06, 'batch_size': 8, 'resize': 100}\n",
      "2025-03-26 00:45:17,454 - INFO - Hyperparameters saved to logs/synthetic_2025-03-25_17-49-28/Sweep_5/hyperparameters.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger initialized. Logs will be saved to: logs/synthetic_2025-03-25_17-49-28/Sweep_5\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/noisy-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/noisy-projections/tilt.rawtlt\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 20% for validation, resulting in 18 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 00:45:20,080 - INFO - Start Training | Epoch: 5 | Dataset size: 940000 | Parameters: {'epochs': 25, 'early_stopping_patience': 5, 'validation_interval': 5, 'scheduler_step_by': 'epoch', 'images_to_visualize': 4, 'pos_enc': 5, 'accum_gradients': 4, 'batch_size': 8, 'beam_samples': 64, 'learning_rate': 5e-06, 'resize': 100} \n",
      "2025-03-26 00:54:54,720 - INFO - Epoch 0 - Training loss: 0.0118\n",
      "2025-03-26 00:55:05,952 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_5/samples/validation_epoch-0_*\n",
      "2025-03-26 00:55:59,912 - INFO - Epoch 0 - Validation loss: 0.0092, MSE: 0.0092\n",
      "2025-03-26 00:55:59,923 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_5/checkpoints/latest_model.pth\n",
      "2025-03-26 00:55:59,934 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_5/checkpoints/best_model.pth (Validation Loss: 0.0092)\n",
      "2025-03-26 00:55:59,935 - INFO - Avg time single epoch: 0h10m39s | Remaining time training: 0h42m39s\n",
      "2025-03-26 00:56:00,005 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_5/plots/training_curves.png\n",
      "2025-03-26 01:05:34,913 - INFO - Epoch 1 - Training loss: 0.0073\n",
      "2025-03-26 01:05:47,137 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_5/samples/validation_epoch-1_*\n",
      "2025-03-26 01:06:41,317 - INFO - Epoch 1 - Validation loss: 0.0079, MSE: 0.0079\n",
      "2025-03-26 01:06:41,328 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_5/checkpoints/latest_model.pth\n",
      "2025-03-26 01:06:41,341 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_5/checkpoints/best_model.pth (Validation Loss: 0.0079)\n",
      "2025-03-26 01:06:41,342 - INFO - Avg time single epoch: 0h10m40s | Remaining time training: 0h32m1s\n",
      "2025-03-26 01:06:41,413 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_5/plots/training_curves.png\n",
      "2025-03-26 01:16:20,757 - INFO - Epoch 2 - Training loss: 0.0068\n",
      "2025-03-26 01:16:33,231 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_5/samples/validation_epoch-2_*\n",
      "2025-03-26 01:17:27,754 - INFO - Epoch 2 - Validation loss: 0.0084, MSE: 0.0084\n",
      "2025-03-26 01:17:27,766 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_5/checkpoints/latest_model.pth\n",
      "2025-03-26 01:17:27,767 - INFO - No improvement in validation loss. Patience counter: 1/5\n",
      "2025-03-26 01:17:27,768 - INFO - Avg time single epoch: 0h10m42s | Remaining time training: 0h21m25s\n",
      "2025-03-26 01:17:27,853 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_5/plots/training_curves.png\n",
      "2025-03-26 01:26:59,915 - INFO - Epoch 3 - Training loss: 0.0065\n",
      "2025-03-26 01:27:12,254 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_5/samples/validation_epoch-3_*\n",
      "2025-03-26 01:28:09,445 - INFO - Epoch 3 - Validation loss: 0.0074, MSE: 0.0074\n",
      "2025-03-26 01:28:09,458 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_5/checkpoints/latest_model.pth\n",
      "2025-03-26 01:28:09,470 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_5/checkpoints/best_model.pth (Validation Loss: 0.0074)\n",
      "2025-03-26 01:28:09,471 - INFO - Avg time single epoch: 0h10m42s | Remaining time training: 0h10m42s\n",
      "2025-03-26 01:28:09,553 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_5/plots/training_curves.png\n",
      "2025-03-26 01:37:45,473 - INFO - Epoch 4 - Training loss: 0.0063\n",
      "2025-03-26 01:37:57,769 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Sweep_5/samples/validation_epoch-4_*\n",
      "2025-03-26 01:38:54,175 - INFO - Epoch 4 - Validation loss: 0.0071, MSE: 0.0071\n",
      "2025-03-26 01:38:54,187 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_5/checkpoints/latest_model.pth\n",
      "2025-03-26 01:38:54,199 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/Sweep_5/checkpoints/best_model.pth (Validation Loss: 0.0071)\n",
      "2025-03-26 01:38:54,200 - INFO - Avg time single epoch: 0h10m42s | Remaining time training: 0h0m0s\n",
      "2025-03-26 01:38:54,284 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/Sweep_5/plots/training_curves.png\n",
      "2025-03-26 01:38:54,285 - INFO - Hyperparameters: {'learning_rate': 5e-06, 'batch_size': 8, 'resize': 100}, Validation Loss: 0.007112591903705513\n",
      "2025-03-26 01:38:54,286 - INFO - Avg time single sweep: 1h18m11s | Remaining_time: 0h0m0s\n",
      "2025-03-26 01:38:54,286 - INFO - Best Parameters: {'learning_rate': 5e-05, 'batch_size': 8, 'resize': 100, 'val_loss': np.float64(0.006018673521477177)}, Best Loss: 0.006018673521477177, Best Sweep index: 3\n",
      "2025-03-26 01:38:54,287 - INFO - Finished sweep with best validation loss = 0.006018673521477177.\n",
      "2025-03-26 01:38:54,288 - INFO - Will use these hyperparameters: {'learning_rate': 5e-05, 'batch_size': 8, 'resize': 100, 'val_loss': np.float64(0.006018673521477177)}\n"
     ]
    }
   ],
   "source": [
    "best_config = None\n",
    "hyperparameter_tuner.update_config(form)\n",
    "print(\"Sweep config:\")\n",
    "for k in hyperparameter_tuner.config['hyperparameter'].keys():\n",
    "    print(f\"\\t{k}: {hyperparameter_tuner.config['hyperparameter'][k]['values']} (default: {hyperparameter_tuner.config['hyperparameter'][k]['default']})\")\n",
    "best_config = hyperparameter_tuner.tune()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our automatic hyperparameter tuning is able to find the best performing set of hyperparameters based on the setting shown above. \n",
    "\n",
    "However, there can be scenarios, where additional flexibility is required. Therefore, you are able to change these hyperparameters in the following. \n",
    "\n",
    "**WARNING** This setting is for advanced users only. Please only change parameters here, if you know what you are doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4364c80ce21244a6936edb9361188689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Best hyperparameters</h2><p>Found best hyperparameters (val_loss = 0.0060) for â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "form = hyperparameter_tuner.edit_hyperparameters()\n",
    "display(form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]::Will use following hyperparameters for future training: {'learning_rate': 5e-05, 'batch_size': 8, 'resize': 100}\n"
     ]
    }
   ],
   "source": [
    "best_config = hyperparameter_tuner.update_hyperparameters(form)\n",
    "print_info(f\"Will use following hyperparameters for future training: {best_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Training and Validation\n",
    "\n",
    "Training in deep learning is the process where a model learns patterns from labeled data by optimizing its parameters through backpropagation. \n",
    "Validation involves using a separate dataset to evaluate the model's performance during training, ensuring it generalizes well to unseen data.\n",
    "Hence, in this section we train and validate the model based on the provided data and hyperparameters resulting from the previous sweep.\n",
    "\n",
    "If no sweep was conducted (not recommended for new datasets!), the default parameters, defined by the DL expert will be used. \n",
    "\n",
    "In case the training run was cancelled, it can be resumed from a previous checkpoint. To do so, you need to provide a model checkpoint in the text form below. You can find these checkpoints inside the runs logging directory (`<log-dir>/TrainingRun/checkpoints/latest_model.pth`). If you do not wish to resume training, you can ignore the text form below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140db2b98b994025b3543162a0efa661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Resume Training:', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452d7a508abb469094481171382fd56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>Hint:</b> If you wish to resume an earlier training, enter the path to the latest_model.pth filâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resume_widget = create_text_widget(\"Resume Training:\",\"\",\"If you wish to resume an earlier training, enter the path to the latest_model.pth file here.\")\n",
    "display(*resume_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 01:38:54,487 - INFO - Hyperparameters saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/hyperparameters.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger initialized. Logs will be saved to: logs/synthetic_2025-03-25_17-49-28/TrainingRun\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/noisy-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/noisy-projections/tilt.rawtlt\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 20% for validation, resulting in 18 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "resume_training = resume_widget[0].value\n",
    "if(resume_training):\n",
    "    resume_training = Path(resume_training)\n",
    "    if(resume_training.is_dir()):\n",
    "        resume_training = Path(find_file(resume_training, \"latest_model.pth\")) \n",
    "        # resume_training = Path(os.path.join(resume_training,\"latest_model.pth\"))\n",
    "    if(not resume_training.is_file()):\n",
    "        logger.log_error(f\"Could not find resume path at {resume_training}. Will start training from scatch.\")\n",
    "        resume_training = None\n",
    "    else: \n",
    "        logger.log_info(f\"Will resume training from {resume_training}\")\n",
    "else:\n",
    "    resume_training = None\n",
    "logger.init(\"TrainingRun\")\n",
    "model_trainer.resume_from_checkpoint = resume_training\n",
    "model_trainer.prepare(best_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to train a model, execute the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 01:38:57,082 - INFO - Start Training | Epoch: 25 | Dataset size: 940000 | Parameters: {'epochs': 25, 'early_stopping_patience': 5, 'validation_interval': 5, 'scheduler_step_by': 'epoch', 'images_to_visualize': 4, 'pos_enc': 5, 'accum_gradients': 4, 'batch_size': 8, 'beam_samples': 64, 'learning_rate': 5e-05, 'resize': 100} \n",
      "2025-03-26 01:48:22,734 - INFO - Epoch 0 - Training loss: 0.0070\n",
      "2025-03-26 01:48:35,619 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/TrainingRun/samples/validation_epoch-0_*\n",
      "2025-03-26 01:49:31,797 - INFO - Epoch 0 - Validation loss: 0.0068, MSE: 0.0068\n",
      "2025-03-26 01:49:31,808 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/checkpoints/latest_model.pth\n",
      "2025-03-26 01:49:31,820 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/checkpoints/best_model.pth (Validation Loss: 0.0068)\n",
      "2025-03-26 01:49:31,821 - INFO - Avg time single epoch: 0h10m34s | Remaining time training: 4h13m53s\n",
      "2025-03-26 01:49:31,907 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 01:59:05,485 - INFO - Epoch 1 - Training loss: 0.0058\n",
      "2025-03-26 01:59:05,486 - INFO - Avg time single epoch: 0h10m4s | Remaining time training: 3h51m35s\n",
      "2025-03-26 01:59:05,565 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 02:08:44,469 - INFO - Epoch 2 - Training loss: 0.0056\n",
      "2025-03-26 02:08:44,470 - INFO - Avg time single epoch: 0h9m55s | Remaining time training: 3h38m26s\n",
      "2025-03-26 02:08:44,563 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 02:18:23,380 - INFO - Epoch 3 - Training loss: 0.0055\n",
      "2025-03-26 02:18:23,381 - INFO - Avg time single epoch: 0h9m51s | Remaining time training: 3h27m1s\n",
      "2025-03-26 02:18:23,467 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 02:27:57,500 - INFO - Epoch 4 - Training loss: 0.0054\n",
      "2025-03-26 02:27:57,501 - INFO - Avg time single epoch: 0h9m48s | Remaining time training: 3h16m0s\n",
      "2025-03-26 02:27:57,593 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 02:37:31,604 - INFO - Epoch 5 - Training loss: 0.0054\n",
      "2025-03-26 02:37:43,966 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/TrainingRun/samples/validation_epoch-5_*\n",
      "2025-03-26 02:38:40,978 - INFO - Epoch 5 - Validation loss: 0.0058, MSE: 0.0058\n",
      "2025-03-26 02:38:40,991 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/checkpoints/latest_model.pth\n",
      "2025-03-26 02:38:41,004 - INFO - Best model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/checkpoints/best_model.pth (Validation Loss: 0.0058)\n",
      "2025-03-26 02:38:41,004 - INFO - Avg time single epoch: 0h9m57s | Remaining time training: 3h9m7s\n",
      "2025-03-26 02:38:41,095 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 02:48:21,089 - INFO - Epoch 6 - Training loss: 0.0054\n",
      "2025-03-26 02:48:21,090 - INFO - Avg time single epoch: 0h9m54s | Remaining time training: 2h58m26s\n",
      "2025-03-26 02:48:21,181 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 02:57:59,656 - INFO - Epoch 7 - Training loss: 0.0053\n",
      "2025-03-26 02:57:59,660 - INFO - Avg time single epoch: 0h9m52s | Remaining time training: 2h47m56s\n",
      "2025-03-26 02:57:59,737 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 03:07:38,851 - INFO - Epoch 8 - Training loss: 0.0053\n",
      "2025-03-26 03:07:38,852 - INFO - Avg time single epoch: 0h9m51s | Remaining time training: 2h37m39s\n",
      "2025-03-26 03:07:38,944 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 03:17:14,476 - INFO - Epoch 9 - Training loss: 0.0053\n",
      "2025-03-26 03:17:14,477 - INFO - Avg time single epoch: 0h9m49s | Remaining time training: 2h27m24s\n",
      "2025-03-26 03:17:14,559 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 03:26:54,464 - INFO - Epoch 10 - Training loss: 0.0053\n",
      "2025-03-26 03:27:07,377 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/TrainingRun/samples/validation_epoch-10_*\n",
      "2025-03-26 03:28:04,086 - INFO - Epoch 10 - Validation loss: 0.0069, MSE: 0.0069\n",
      "2025-03-26 03:28:04,098 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/checkpoints/latest_model.pth\n",
      "2025-03-26 03:28:04,099 - INFO - No improvement in validation loss. Patience counter: 1/5\n",
      "2025-03-26 03:28:04,099 - INFO - Avg time single epoch: 0h9m55s | Remaining time training: 2h18m51s\n",
      "2025-03-26 03:28:04,172 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 03:37:49,292 - INFO - Epoch 11 - Training loss: 0.0053\n",
      "2025-03-26 03:37:49,293 - INFO - Avg time single epoch: 0h9m54s | Remaining time training: 2h8m45s\n",
      "2025-03-26 03:37:49,379 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 03:47:27,087 - INFO - Epoch 12 - Training loss: 0.0053\n",
      "2025-03-26 03:47:27,088 - INFO - Avg time single epoch: 0h9m52s | Remaining time training: 1h58m35s\n",
      "2025-03-26 03:47:27,178 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 03:57:04,515 - INFO - Epoch 13 - Training loss: 0.0053\n",
      "2025-03-26 03:57:04,516 - INFO - Avg time single epoch: 0h9m51s | Remaining time training: 1h48m30s\n",
      "2025-03-26 03:57:04,609 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 04:06:41,191 - INFO - Epoch 14 - Training loss: 0.0052\n",
      "2025-03-26 04:06:41,191 - INFO - Avg time single epoch: 0h9m50s | Remaining time training: 1h38m28s\n",
      "2025-03-26 04:06:41,281 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 04:16:18,104 - INFO - Epoch 15 - Training loss: 0.0052\n",
      "2025-03-26 04:16:30,996 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/TrainingRun/samples/validation_epoch-15_*\n",
      "2025-03-26 04:17:27,567 - INFO - Epoch 15 - Validation loss: 0.0069, MSE: 0.0069\n",
      "2025-03-26 04:17:27,579 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/checkpoints/latest_model.pth\n",
      "2025-03-26 04:17:27,580 - INFO - No improvement in validation loss. Patience counter: 2/5\n",
      "2025-03-26 04:17:27,581 - INFO - Avg time single epoch: 0h9m54s | Remaining time training: 1h29m8s\n",
      "2025-03-26 04:17:27,675 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 04:27:04,163 - INFO - Epoch 16 - Training loss: 0.0052\n",
      "2025-03-26 04:27:04,164 - INFO - Avg time single epoch: 0h9m53s | Remaining time training: 1h19m6s\n",
      "2025-03-26 04:27:04,254 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 04:36:37,571 - INFO - Epoch 17 - Training loss: 0.0052\n",
      "2025-03-26 04:36:37,572 - INFO - Avg time single epoch: 0h9m52s | Remaining time training: 1h9m5s\n",
      "2025-03-26 04:36:37,655 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 04:46:17,216 - INFO - Epoch 18 - Training loss: 0.0052\n",
      "2025-03-26 04:46:17,217 - INFO - Avg time single epoch: 0h9m51s | Remaining time training: 0h59m9s\n",
      "2025-03-26 04:46:17,309 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 04:55:52,963 - INFO - Epoch 19 - Training loss: 0.0052\n",
      "2025-03-26 04:55:52,964 - INFO - Avg time single epoch: 0h9m50s | Remaining time training: 0h49m13s\n",
      "2025-03-26 04:55:53,056 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 05:05:32,922 - INFO - Epoch 20 - Training loss: 0.0052\n",
      "2025-03-26 05:05:45,718 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/TrainingRun/samples/validation_epoch-20_*\n",
      "2025-03-26 05:06:42,229 - INFO - Epoch 20 - Validation loss: 0.0069, MSE: 0.0069\n",
      "2025-03-26 05:06:42,242 - INFO - Current model checkpoint saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/checkpoints/latest_model.pth\n",
      "2025-03-26 05:06:42,243 - INFO - No improvement in validation loss. Patience counter: 3/5\n",
      "2025-03-26 05:06:42,243 - INFO - Avg time single epoch: 0h9m53s | Remaining time training: 0h39m33s\n",
      "2025-03-26 05:06:42,341 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 05:16:22,758 - INFO - Epoch 21 - Training loss: 0.0052\n",
      "2025-03-26 05:16:22,759 - INFO - Avg time single epoch: 0h9m52s | Remaining time training: 0h29m38s\n",
      "2025-03-26 05:16:22,838 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 05:25:56,610 - INFO - Epoch 22 - Training loss: 0.0052\n",
      "2025-03-26 05:25:56,611 - INFO - Avg time single epoch: 0h9m52s | Remaining time training: 0h19m44s\n",
      "2025-03-26 05:25:56,698 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 05:35:37,188 - INFO - Epoch 23 - Training loss: 0.0051\n",
      "2025-03-26 05:35:37,189 - INFO - Avg time single epoch: 0h9m51s | Remaining time training: 0h9m51s\n",
      "2025-03-26 05:35:37,269 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n",
      "2025-03-26 05:45:13,796 - INFO - Epoch 24 - Training loss: 0.0051\n",
      "2025-03-26 05:45:13,796 - INFO - Avg time single epoch: 0h9m50s | Remaining time training: 0h0m0s\n",
      "2025-03-26 05:45:14,134 - INFO - Training curves saved to logs/synthetic_2025-03-25_17-49-28/TrainingRun/plots/training_curves.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.005827395319160439)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Evaluation\n",
    "Evaluation in deep learning is the process of evaluating a trained model on a separate, unseen dataset to measure its final performance. It provides an unbiased assessment of the model's ability to generalize to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Choose Model \n",
    "\n",
    "In this section we choose the model for testing. \n",
    "If you leave the `Model Path` empty in the text form below, it will use the last model trained.\n",
    "Otherwise, you can define the path to the models best weights at `<log-path>/TrainingRun/checkpoints/best_model.pth` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b480c9ee0247fb9d1f60b9c23171b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Model Path:', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8bb639354d3479cb4ae75898e3fd8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>Hint:</b> If you wish to test a specific model, you can here define the path to its checkpoint.â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_widget = create_text_widget(\"Model Path:\",\"\",\"If you wish to test a specific model, you can here define the path to its checkpoint. (For example: logs/tem-herpes_2025-02-03_11-42-43/TrainingRun/checkpoints)\")\n",
    "display(*model_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Evaluate\n",
    "We finally evaluate the provided model on the test set. We investigate following metrics: \n",
    "\n",
    "<span style=\"color:red\"> Add a description of the used metrics here. </span>\n",
    "\n",
    "<span style=\"color:green\">\n",
    "\n",
    "- **Accuracy (Acc)**: The percentage of correct predictions based on all predictions.\n",
    "\n",
    "- **Mean Absolute Error (MAE)**: A distance metric to compute the difference between the prediction and the label. Measures the absolute difference between predicted and actual counts. The lower the metric, the better. \n",
    "\n",
    "- **Mean Absolute Error (MAE-class-name)**: A distance metric to compute the difference between the prediction and the label. Measures the absolute difference between predicted and actual counts for each class individually. This can help to find a specifically well/bad performing class. The lower the metric, the better.\n",
    "</span>\n",
    "\n",
    "\n",
    "<span style=\"color:red\">Add a description of your visualizations here.</span>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These visualizations are saved to `<log-path>/Evaluate/samples/test_*`. \n",
    "\n",
    "If you wish to evaluate a model, execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 07:50:23,226 - INFO - Found most recent log at logs/synthetic_2025-03-25_17-49-28/TrainingRun/checkpoints/best_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::Found 94 images within tilt series at ./data/synthetic/noisy-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/noisy-projections/tilt.rawtlt\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 20% for validation, resulting in 18 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n",
      "INFO::Found 94 images within tilt series at ./data/synthetic/clean-projections/*.tif.\n",
      "INFO::Resized image resolution from (1000, 1000) to (100, 100). Note that strong downscaling can lead to loss of information.\n",
      "INFO::Applied minmax normalization to tilt series. \n",
      " Current max = 1.0000 | Current min = 0.0000\n",
      "INFO:: tilt angles were loaded from ./data/synthetic/clean-projections/tilt.rawtlt\n",
      "INFO::Use 100% for validation, resulting in 94 projection images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 07:50:25,974 - INFO - Resumed training from checkpoint: logs/synthetic_2025-03-25_17-49-28/TrainingRun/checkpoints/best_model.pth (Validation Loss: 0.0058)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger initialized. Logs will be saved to: logs/synthetic_2025-03-25_17-49-28/Evaluate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 07:50:39,444 - INFO - Saved visualizations to logs/synthetic_2025-03-25_17-49-28/Evaluate/samples/test_*\n",
      "2025-03-26 07:55:31,444 - INFO - Test loss: 0.0062\n",
      "2025-03-26 07:55:32,172 - INFO - MSE: 0.0062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loaded data: 255\n",
      "INFO::Original shape of volume (1000, 1000, 1000) was resized to (100, 100, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate Tomogram: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68750/68750 [00:43<00:00, 1566.00it/s]\n",
      "2025-03-26 07:56:16,821 - INFO - Test loss phantom: 0.0481\n",
      "2025-03-26 07:56:16,833 - INFO - Evaluation Tomogram was saved to logs/synthetic_2025-03-25_17-49-28/Evaluate/samples/tomogram.tif\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path \n",
    "start_evaluation = False\n",
    "eval_model = model_widget[0].value\n",
    "if(eval_model):\n",
    "    eval_model = Path(eval_model)\n",
    "    if(eval_model.is_dir()):\n",
    "        eval_model = Path(find_file(eval_model, \"best_model.pth\")) \n",
    "    if(not eval_model.is_file()):\n",
    "        logger.log_error(f\"Could not find model at {eval_model}. Make sure to train a model before evaluation.\")\n",
    "        eval_model = None\n",
    "    else: \n",
    "        start_evaluation = True\n",
    "else:\n",
    "    recent_logs = logger.get_most_recent_logs()\n",
    "    eval_model = \"\"\n",
    "    for dataname, log_path in recent_logs.items():\n",
    "        if(dataname == Path(data_path).stem):\n",
    "            eval_model = Path(log_path+\"/TrainingRun/checkpoints/best_model.pth\")\n",
    "            if(not eval_model.is_file()):\n",
    "                logger.log_error(f\"Cound not find a trained model at {eval_model}. Make sure you fully train a model first before evaluating.\")\n",
    "            else:\n",
    "                logger.log_info(f\"Found most recent log at {eval_model}\")\n",
    "                start_evaluation = True\n",
    "        else: \n",
    "            continue\n",
    "    if(not start_evaluation):\n",
    "        logger.log_error(\"Cound not find a trained model. Make sure you train a model first before evaluating.\")\n",
    "      \n",
    "if(start_evaluation):\n",
    "    model_trainer.load_checkpoint(eval_model)\n",
    "    model_trainer.test()      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
